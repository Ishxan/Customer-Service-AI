---
title: "Project_2"
author: "Ishkhan Elazyan"
date: "04/08/2021"
output:
  html_document:
    theme: readable
    highlight: breezedark
    number_sections: yes
    toc: yes
    fig_width: 10
    fig_height: 5
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load dependencies

```{r}
require(devtools)
require(quanteda)
library("quanteda.dictionaries")
require(quanteda.textstats)
require(quanteda.textplots)
require(quanteda.corpora)
library(tidyverse)
library(rtweet)
library(twitteR)
library(sentimentr)
library(caret)
library(broom)
library(tidytext)
get_sentiments("nrc")
library(dplyr)
library(tidyr)
library(topicmodels)
library(ldatuning)
```

## Load and prepare the data

```{r Load and prepare the data}

review_raw <- read.csv(file = "Musical_instruments_reviews.csv")
summary(review_raw)

head(review_raw)
 
#preprocessing
review_raw_token <- tokens(review_raw$reviewText, what = "word",
                             remove_numbers = TRUE, remove_punct = TRUE, remove_symbols = TRUE, 
                           remove_hyphens = TRUE)
head(review_raw_token)

review_raw_dfm <- review_raw_token %>% 
  tokens_remove(stopwords(source = "smart")) %>% 
  tokens_wordstem() %>% 
  tokens_tolower() %>% 
  dfm()

review_raw_dfm

tokenfreq<-textstat_frequency(review_raw_dfm, n=100)#Uses Quanteda
head(tokenfreq, 10)

tokenfreq1<-data.frame(rowSums(review_raw_dfm))
colnames(tokenfreq1)<-"Freq"
summary(tokenfreq1)

#shows that the Tweeters used around 18 characters per Tweet
ggplot(tokenfreq1, aes(x = Freq)) +
geom_histogram(binwidth = 1) +
labs(y = "Number of Documents", x = "Tokens Count Per Document",
title = "Distribution of Tokens per Document")

textplot_wordcloud(
  review_raw_dfm,
  min_size = 0.5,
  max_size = 4,
  min_count = 10,
  max_words = 200,
  color = "darkblue",
  font = NULL,
  adjust = 0,
  rotation = 0.1,
  random_order = FALSE,
  random_color = FALSE,
  ordered_color = FALSE,
  labelcolor = "gray20",
  labelsize = 1.5,
  labeloffset = 0,
  fixed_aspect = TRUE,
  comparison = FALSE
)
```
## Sentiment Analysis

```{r creating Bing dictionary for Sentiment Analysis}

corp_review <- corpus(review_raw, text_field = "reviewText")
positive_bing <- scan("positive-words.txt", what = "char", sep = "\n", skip = 35, quiet = T)
negative_bing <- scan("negative-words.txt", what = "char", sep = "\n", skip = 35, quiet = T)

sentiment_bing <- dictionary(list(positive = positive_bing, negative = negative_bing))

```


```{r creating the dfm sentiment}
dfm_sentiment <- dfm(corp_review, dictionary = sentiment_bing)
dfm_sentiment
```


```{r using our sentiment dfm}
dfm_sentiment_df <- convert(dfm_sentiment, to = "data.frame")
dfm_sentiment_df$net <- (dfm_sentiment_df$positive)-(dfm_sentiment_df$negative)
summary(dfm_sentiment_df)
head(dfm_sentiment_df)
dfm_sentiment_df_negative <- subset(dfm_sentiment_df, net < -2)
dfm_sentiment_df_negative <- dfm_sentiment_df_negative
dfm_sentiment_df_negative

textId <- c()
nrow(review_raw)
for (i in 1:nrow(review_raw)) {
  textId[i] <- gsub(" ", "", paste('text', i))
}
review_raw$textId <- as.factor(textId)
review_raw_negative <- filter(review_raw, review_raw$textId %in% dfm_sentiment_df_negative$doc_id) %>% arrange(textId)
summary(review_raw_negative)
```

```{r}
dfm_sentiment_propreview <- dfm_weight(dfm_sentiment, scheme = "prop")
dfm_sentiment_propreview

sentiment_review <- convert(dfm_sentiment_propreview, "data.frame") %>%
  gather(positive, negative, key = "Polarity", value = "Share") %>%
  mutate(doc_id = as_factor(doc_id)) %>%
  rename(Review = doc_id)

sentiment_review_negative <- subset(sentiment_review, Polarity=='negative')
head(sentiment_review)
head(sentiment_review_negative)

ggplot(sentiment_review, aes(Review, Share, fill = Polarity, group = Polarity)) +
geom_bar(stat='identity', position = position_dodge(), size = 1) +
scale_fill_brewer(palette = "Set1") +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
ggtitle("Sentiment scores in review Reviews (relative)")

```

## Creating LDA for our data

```{r LDA}
#LDA
set.seed(111)
review_raw_samp <-review_raw_negative[sample(nrow(review_raw_negative), 200), ]#
head(review_raw_samp)
review_raw_token2 <- tokens(review_raw_samp$reviewText, what = "word",
                            remove_numbers = TRUE, remove_punct = TRUE,
                            remove_symbols = TRUE)
review_raw_dfm<-review_raw_token2 %>%
  tokens_remove(stopwords(source = "smart")) %>%
  tokens_wordstem() %>%
  tokens_tolower() %>%
  dfm()
#dfm_trim(min_docfreq = 0.01, max_docfreq = 0.90, docfreq_type = "prop")
#head(review_raw_dfm)

textId <- c()
nrow(review_raw_dfm)
for (i in 1:nrow(review_raw_dfm)) {
  textId[i] <- gsub(" ", "", paste('text', i))
}
review_raw_samp$textId <- as.factor(textId)
review_raw_samp

perplexArray <- c()

for (val in 2:50) {
  print(val)

review_lda <-LDA(review_raw_dfm, val, method="Gibbs", control=list(iter = 200, verbose = 25))

ldaResult <- posterior(review_lda)

perplexArray[val - 1] <- text2vec::perplexity(review_raw_dfm, ldaResult$terms, ldaResult$topics)
}

K <- which.min(perplexArray) + 1 # with this method the optimal value for K is 22. For simplicity I will use only 4
K 

K <- 4

review_raw_dfm
review_lda <-LDA(review_raw_dfm, K, method="Gibbs",control=list(iter = 200, verbose = 25))

term_topics <- tidy(review_lda, matrix = "beta")#Topic Term Probabilities # we tidy it up to use tidytext package
term_topics
```




```{r plotting our results}
top_terms <- term_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
arrange(topic, -beta)
top_terms

top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free")
```
```{r document to topic distribution}
review_documents <- tidy(review_lda, matrix = "gamma")
document_to_topic <- review_documents %>% group_by(document) %>% top_n(1, gamma)
document_to_topic
document_to_topic <- document_to_topic %>% group_by(topic)  %>% top_n(5, gamma)
```

```{r first topic}
topic_name <- c()
topic_answer <- c()
first_topic_docs <- subset(document_to_topic, topic==1)
first_topic_docs_text <- filter(review_raw_samp, review_raw_samp$textId %in% first_topic_docs$document)$reviewText
topic_name[1] = 'pedal_issues'
topic_answer[1] = "Please read carefully the manual before using the product, use a different pedal or contact us for a refund or a techical assistance."
```

```{r second topic}
second_topic_docs <- subset(document_to_topic, topic==2)
second_topic_docs_text <- filter(review_raw_samp, review_raw_samp$textId %in% second_topic_docs$document)$reviewText
topic_name[2] = 'noice_issue'
topic_answer[2] = "If you experiencing noice issue while using our product that means there is an installation problem. Please refer to this manual https://www.howtononoice.com/angry/customer for a detailed instruction."
```

```{r third topic}
third_topic_docs <- subset(document_to_topic, topic==3)
third_topic_docs_text <- filter(review_raw_samp, review_raw_samp$textId %in% third_topic_docs$document)$reviewText
topic_name[3] = "problem_with_strings"
topic_answer[3] = "This is a common problem. A system of strongly interacting strings can, in some cases, behave as a system of weakly interacting strings which results in  a bad sound. Please contant one of our representatives - Ashoke Sen((801)122 2888) for details."
```

```{r forth topic}
forth_topic_docs <- subset(document_to_topic, topic==4)
forth_topic_docs_text <- filter(review_raw_samp, review_raw_samp$textId %in% forth_topic_docs$document)$reviewText
topic_name[4] = "bad_quality_cable"
topic_answer[4] = "Sorry for hearing that. For now, we will do our best to sell as much product as possible but if quality becomes something that affects our sales we promise to focus on that."
``` 

```{r}
topic_name
topic_answer
```

## 

```{r }

sentimentOfText <- function(dict, text) {
  dfm_sentiment_text <- dfm(text, dictionary = dict)
  dfm_sentiment_df_text <- convert(dfm_sentiment_text, to = "data.frame")
  print(dfm_sentiment_df_text$positive)
  print(dfm_sentiment_df_text$negative)
  if(dfm_sentiment_df_text$positive - dfm_sentiment_df_text$negative < 0) {
    return('negative')
  }
  else {
    return('positive')
  }
}

topicOfText <- function(model, text) {
  text_token <- tokens(text, what = "word",
                            remove_numbers = TRUE, remove_punct = TRUE,
                            remove_symbols = TRUE)
  text_token_dfm<-text_token %>%
  tokens_remove(stopwords(source = "smart")) %>%
  tokens_wordstem() %>%
  tokens_tolower() %>%
  dfm()
  x <- posterior(model, text_token_dfm)$topics
  x <- as.data.frame(x)
  result <- colnames(x)[apply(x,1,which.max)]
  return(strtoi(result))
}
```

```{r}
text <- 'very bad not working broken unfunctional haha-guitar model 123 omegalul wtf genius cable noice bad quality'
topicOfText(review_lda, text)
sentimentOfText(sentiment_bing, text)

#saveRDS(review_lda, "lda.rds")
#save(topic_name, file = "topic_name.rda")
#save(topic_answer, file = "topic_answer.rda")

```









